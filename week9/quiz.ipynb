{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local\", \"quiz\")\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋\n",
    "id; age; gender; height; weitht; ap_hi; ap_lo; cholesterol; gluc; smoke; alco; active; cardio\n",
    "\n",
    "(cardio는 클래스, id는 데이터 인덱스)  \n",
    "전체 데이터 중 60%는 학습용, 40%는 검증용으로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.textFile(\"cardio_train.csv\").flatMap(lambda l: l.split('\\n')).map(lambda l: l.split(';'))\n",
    "data = np.array(data.collect()[1:]).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.6\n",
    "train_size = int(train_ratio*len(data))\n",
    "valid_size = len(data) - train_size\n",
    "shuffled_idx = np.random.permutation(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000e+00 2.0312e-02 2.0000e-06 1.7000e-04 7.8000e-05 1.5000e-04\n",
      "  1.0000e-04 1.0000e-06 1.0000e-06 0.0000e+00 0.0000e+00 1.0000e-06\n",
      "  1.0000e+00]\n",
      " [1.0000e+00 1.7571e-02 1.0000e-06 1.6200e-04 6.1000e-05 1.2000e-04\n",
      "  7.0000e-05 1.0000e-06 1.0000e-06 0.0000e+00 0.0000e+00 1.0000e-06\n",
      "  0.0000e+00]\n",
      " [1.0000e+00 1.9005e-02 2.0000e-06 1.8000e-04 1.0600e-04 1.3000e-04\n",
      "  9.0000e-05 3.0000e-06 1.0000e-06 1.0000e-06 0.0000e+00 1.0000e-06\n",
      "  1.0000e+00]]\n"
     ]
    }
   ],
   "source": [
    "train = data[shuffled_idx[:train_size]]*0.000001\n",
    "valid = data[shuffled_idx[train_size:]]*0.000001 # 오버플로우 방지용 범위 조절\n",
    "D = len(train[0])-1 #feature \n",
    "\n",
    "train[:, 0] = 1 # bias(b0)를 위한 feature\n",
    "valid[:, 0] = 1\n",
    "train[:, D] *= 1000000\n",
    "valid[:, D] *= 1000000\n",
    "\n",
    "train_RDD = sc.parallelize(train)\n",
    "valid_RDD = sc.parallelize(valid)\n",
    "print(train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w: [-3.90472795e-02  1.98277526e+00 -5.09979689e-06  4.99932761e+00\n",
      "  1.09999750e+01  6.00037191e+00  3.00097071e+00  1.00000103e+01\n",
      "  9.00000037e+00  6.99999924e+00  7.99999963e+00  9.99995349e-01]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "maxIter = 50\n",
    "learning_rate = 0.0001\n",
    "\n",
    "w = np.random.permutation(D).astype(np.float) # 각 feature의 가중치 벡터\n",
    "\n",
    "for _ in range(maxIter):\n",
    "    gradient = train_RDD.map(lambda p: (p[D] - 1/(1+math.exp(-np.dot(w,p[:D]))))*p[:D])\\\n",
    "                    .reduce(lambda a, b: a+b)\n",
    "    w += learning_rate * np.array(gradient)\n",
    "\n",
    "print(\"Final w: {}\".format(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 검증\n",
    "\n",
    "학습된 가중치와 검증 데이터셋으로 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.59078574\n"
     ]
    }
   ],
   "source": [
    "y = valid[:,D]\n",
    "y_pred = list()\n",
    "\n",
    "for i, v in enumerate(valid):\n",
    "    y_pred.append(1 / (1 + np.exp(-np.dot(w, v[:D]))))\n",
    "    \n",
    "correct_pred = np.equal(np.round(y_pred), y.astype(np.int64))\n",
    "print(\"accuracy: \", np.mean(correct_pred.astype(np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
